{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f3b5b40-8b64-44b8-906e-288ffd1ffd48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:04:07.279144Z",
     "iopub.status.busy": "2023-12-13T18:04:07.278887Z",
     "iopub.status.idle": "2023-12-13T18:04:07.528724Z",
     "shell.execute_reply": "2023-12-13T18:04:07.527599Z",
     "shell.execute_reply.started": "2023-12-13T18:04:07.279115Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from classes import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cad15b3-d5e0-4db2-81be-599736829e53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:04:07.529977Z",
     "iopub.status.busy": "2023-12-13T18:04:07.529682Z",
     "iopub.status.idle": "2023-12-13T18:04:07.534764Z",
     "shell.execute_reply": "2023-12-13T18:04:07.533788Z",
     "shell.execute_reply.started": "2023-12-13T18:04:07.529956Z"
    }
   },
   "outputs": [],
   "source": [
    "## URIs\n",
    "NESSIE_URI = os.environ.get(\"NESSIE_URI\")\n",
    "\n",
    "## MINIO KEys\n",
    "MINIO_REGION = os.environ.get(\"MINIO_REGION\")\n",
    "AWS_ACCESS_KEY = os.environ.get(\"MINIO_ACCESS_KEY\")\n",
    "AWS_SECRET_KEY = os.environ.get(\"MINIO_SECRET_KEY\")\n",
    "AWS_S3_ENDPOINT = \"http://minio:9000\"\n",
    "\n",
    "## BUCKETS\n",
    "BRONZE = os.environ.get(\"BRONZE\")\n",
    "SILVER = os.environ.get(\"SILVER\")\n",
    "GOLD = os.environ.get(\"GOLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63339cd-7495-45d2-a6cf-892b9ae667b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:04:07.537213Z",
     "iopub.status.busy": "2023-12-13T18:04:07.536784Z",
     "iopub.status.idle": "2023-12-13T18:04:14.241851Z",
     "shell.execute_reply": "2023-12-13T18:04:14.241036Z",
     "shell.execute_reply.started": "2023-12-13T18:04:07.537190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.10/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "software.amazon.awssdk#bundle added as a dependency\n",
      "software.amazon.awssdk#url-connection-client added as a dependency\n",
      "org.apache.iceberg#iceberg-spark-runtime-3.2_2.12 added as a dependency\n",
      "org.projectnessie.nessie-integrations#nessie-spark-extensions-3.2_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-462c17ac-a54b-4471-859c-3a7d12cf5e90;1.0\n",
      "\tconfs: [default]\n",
      "\tfound software.amazon.awssdk#bundle;2.17.178 in central\n",
      "\tfound software.amazon.eventstream#eventstream;1.0.1 in central\n",
      "\tfound software.amazon.awssdk#url-connection-client;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#utils;2.17.178 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound software.amazon.awssdk#annotations;2.17.178 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound software.amazon.awssdk#http-client-spi;2.17.178 in central\n",
      "\tfound software.amazon.awssdk#metrics-spi;2.17.178 in central\n",
      "\tfound org.apache.iceberg#iceberg-spark-runtime-3.2_2.12;1.4.2 in central\n",
      "\tfound org.projectnessie.nessie-integrations#nessie-spark-extensions-3.2_2.12;0.74.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 380ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.iceberg#iceberg-spark-runtime-3.2_2.12;1.4.2 from central in [default]\n",
      "\torg.projectnessie.nessie-integrations#nessie-spark-extensions-3.2_2.12;0.74.0 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tsoftware.amazon.awssdk#annotations;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#http-client-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#metrics-spi;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#url-connection-client;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.awssdk#utils;2.17.178 from central in [default]\n",
      "\tsoftware.amazon.eventstream#eventstream;1.0.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   14  |   0   |   0   |   0   ||   14  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-462c17ac-a54b-4471-859c-3a7d12cf5e90\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 14 already retrieved (0kB/8ms)\n",
      "23/12/13 18:04:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3dbd3927f4bf:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Teste_Function</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7f4008c1c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = f.getOrCreateSparkSession(\n",
    "    app_name = 'Teste_Function',\n",
    "    uri = NESSIE_URI,\n",
    "    aws_endpoint = AWS_S3_ENDPOINT,\n",
    "    access_key = 'brNYd3v4uwt2lgGepJU8',\n",
    "    secret_key = 'eUp8c78ChwLWFK4HMrvg2KKzuZjsm6S0yl4uQXCU',\n",
    "    bucket = SILVER\n",
    ")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc24b707-b35d-4833-b6ed-0aae7216208d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:04:14.243348Z",
     "iopub.status.busy": "2023-12-13T18:04:14.243097Z",
     "iopub.status.idle": "2023-12-13T18:04:18.298217Z",
     "shell.execute_reply": "2023-12-13T18:04:18.297315Z",
     "shell.execute_reply.started": "2023-12-13T18:04:14.243322Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/13 18:04:14 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"s3a://bronze/raw_files/channels.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edfb5e7d-7bc4-4a7d-a994-fc21a779ece4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:04:57.391297Z",
     "iopub.status.busy": "2023-12-13T18:04:57.390643Z",
     "iopub.status.idle": "2023-12-13T18:04:57.514209Z",
     "shell.execute_reply": "2023-12-13T18:04:57.513419Z",
     "shell.execute_reply.started": "2023-12-13T18:04:57.391266Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+\n",
      "|channel_id|channel_name|channel_type|\n",
      "+----------+------------+------------+\n",
      "|         1| OTHER PLACE| OWN CHANNEL|\n",
      "|         2| PHONE PLACE| OWN CHANNEL|\n",
      "|         3| WHATS PLACE| OWN CHANNEL|\n",
      "|         4|  FACE PLACE| OWN CHANNEL|\n",
      "+----------+------------+------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8255c6a9-d183-4c1f-be60-3574432a7c70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-13T18:05:48.487419Z",
     "iopub.status.busy": "2023-12-13T18:05:48.486714Z",
     "iopub.status.idle": "2023-12-13T18:05:51.520360Z",
     "shell.execute_reply": "2023-12-13T18:05:51.519354Z",
     "shell.execute_reply.started": "2023-12-13T18:05:48.487381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.format(\"iceberg\").saveAsTable(\"nessie.dim_channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3ef94-74ae-47c9-895a-c5986408a3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
